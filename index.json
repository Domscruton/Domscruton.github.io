[{"authors":null,"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n  Download my resumé.\n","date":1372636800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1372636800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Nelson Bighetti","type":"authors"},{"authors":null,"categories":null,"content":"I\u0026rsquo;m a Graduate Data Scientist in Household Risk \u0026amp; Retail Pricing at Admiral Group PLC, a FTSE 100 Insurance firm.\nMy work involves optimizing the pricing structure through advanced and traditional Statistical Modelling and Machine Learning approaches. I am particularly interested in Stochastic Optimization, Statistical Inference and Bayesian Machine Learning (and its applications in Reinforcement Learning and Bayesian Networks).\n  Download my resumé.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cc46d9ce78a2d7ec82db57f9c44aad94","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I\u0026rsquo;m a Graduate Data Scientist in Household Risk \u0026amp; Retail Pricing at Admiral Group PLC, a FTSE 100 Insurance firm.\nMy work involves optimizing the pricing structure through advanced and traditional Statistical Modelling and Machine Learning approaches.","tags":null,"title":"Dominic Scruton","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://domscruton.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://domscruton.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://domscruton.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Nelson Bighetti","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://domscruton.github.io/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://domscruton.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"\rGLMs - A Natural Extension of the Linear Model\rThe first model we naturally learn on any statistics-based course is Simple Linear Regression (SLR). Despite placing strong (linear) assumptions on the relationship between the response and covariates, as well as the error distribution if we are interested in statistical inference, the Linear model is a surprisingly useful tool for representing many natural processes. However, when we wish to deal with non-linear random variable generating processes, such as the probability of occurrence of an event from a binary or multinomial distribution, or for the modelling of counts within a given time period, we need to generalize the Linear Model.\nGeneralized Linear Models enable us to explicitly model the mean of a distribution from the exponential family, such that predictions lie in a feasible range and the relationship between the mean and the variance is appropriate to perform reliable inference. In this brief blog we discuss the intuition behind the Generalized Linear Model and Link function and prove the method of Iteratively ReWeighted Least Squares enables us to fit a GLM, before implementing it in R.\nGeneralized Linear Models have 3 components:\n1) Random Component Error Structure\n\\[y_i \\sim exponential \\; family \\; distibution\\]\nWe also typically assume each \\(y_i\\) is independent and identically distributed, although this assumption can be relaxed through the use of Generalized Estimating Equations (GEE's).\n2) Systematic Component/ Linear Predictor\n\\[\\eta_i = \\beta_0 + \\sum_{i = 1}^{p}\\beta_p x_{i, p}\\]\n3) Link Function\n\\[\\mathop{\\mathbb{E}}[y_i | x_{1, i}, ..., x_{p, i}] = \\mu_i\\] \\[g(\\mu_i) = \\eta_i\\]\nIt should be made clear that we are not modellig the response \\(y_i\\) explicitly, but rather modelling the mean of the distibution, \\(\\mu_i\\). Predictions for each observation \\(i\\) are given by \\(\\mu_i\\), with each \\(y_i\\) assumed to be centred around \\(\\mu_i\\) in expectation but with an error term that has a distibution specified by the member of the exponential family used. Therefore, the link function does not transform the response \\(y_i\\) but instead transforms the mean \\(\\mu_i\\). Note that the linear model is a specific type of GLM, where \\(y_i \\sim Normal\\) and \\(g(\\mu_i) = \\mu_i = \\eta_i = \\beta_0 + \\sum_{i = 1}^{p}\\beta_p x_{i, p}\\). For a Poisson GLM, each \\(y_i\\) is a r.v. simulated from the Poisson distribution with mean \\(\\mu_i\\), hence \\(y_i\\) has a Poisson error distribution, the difference between \\(y_i\\) and \\(\\hat{y_i} = \\mu_i\\).\n\rLink Functions\rSo Generalized Linear models are simply a natural extension of the Linear Model. They differ through the explicit introduction of a link function (the link function for the linear model is simply the identity, \\(g(\\mu) = \\mu\\)) and through the specification of a mean-variance relationship (the response belongs to a member of the exponential family). Using a link function allows us to transform values of the linear predictor to predictions of the mean, such that these predictions are always contained within the range of possible values for the mean, \\(\\mu_i\\).\nWhen choosing a link function, there is no 'correct' choice, however there are a few properties we require to be able to interpret and fit a model:\nThe link function transforms the linear predictor such that the prediction of \\(\\mu_i\\) for each \\(y_i\\) is within the range of possible values of \\(\\mu\\).\n\rThe link function must be monotonic and therefore have a unique inverse. That is, each value on the linear predictor must be mapped to a unique value of the mean and the link function must preserve the order/ranking of predictions.\n\rThe link function must be differentiable, in order to estimate model coefficients.\n\r\rFor OLS, the linear predictor \\(X\\beta\\) can take on any value in the range \\((-\\infty, \\infty)\\). For a Poisson model, we require the rate parameter \\(\\mu\\) (equivalent to the commonly used \\(\\lambda\\)), to lie in the range \\((0, \\infty)\\), thus we need a link function that transforms the linear predictor \\(\\eta\\) to lie in this range. The common choice of link function for a Poisson GLM is the log-link (\\(\\log(\\mu_i) = \\eta_i\\)). Exponentiating the linear predictor results in \\(\\mu_i \\in (0, \\infty)\\) as required for count data modeled via a Poisson. The log-link also results in a nice interpretation, since it exponentiates the linear predictor resulting in a multiplication of exponentiated coefficients: \\(log(\\mu_i) = exp(\\b_0 + \\beta_1 x_{1, i}) = \\exp(\\beta_0) \\exp(\\beta_1 x_{1, i})\\). Note that we can't use the square root function as a link function since it does not have a unique inverse (i.e. \\(\\sqrt(4) = \\pm 2\\)).\nFor the Binomial, we choose a link function that maps \\(p_i\\), the probability of success to the interval \\([0, 1]\\). The link function \\(g(\\mu_i) = log(\\frac{p_i}{n - p_i}) = X \\beta_i\\) is one candidate. This transforms the Linear predictor: \\(\\frac{p_i}{1 - p_i} = \\exp(X \\beta_i)\\) \\(\\implies p_i = (\\frac{e^{X \\beta_i}}{1 + e ^ {X \\beta_i}}) \\in [0, 1]\\) to the required range.\nWhilst we are able to choose any link function that satisfies these properties, the usual choice is to select the Canonical link function, which arises from writing the distribution in its exponential form. These link functions have nice mathematical properties and simplify the derivation of the Maximum Likelihood Estimators. We could also use an Information Criteria such as AIC to choose the best-fitting link function, although there is typically little deviation in performance, so we typically choose the link function with the most intuitive interpretation (which is often the canonical link function anyway).\nSome common distributions and Canonical links are show below:\n\r\r\r\rFamily\rCanonical Link (\\(\\eta = g(\\mu)\\))\rInverse Link (\\(\\mu = g^{-1}(\\eta)\\))\r\r\r\rBinomial\rLogit: \\(\\eta = log \\left( \\frac{\\mu}{n - \\mu} \\right)\\)\r\\(\\mu = \\frac{n}{1 + e^{-n}}\\)\r\rGaussian\rIdentity: \\(\\eta = \\mu\\)\r\\(\\mu = \\eta\\)\r\rPoisson\rLog: \\(\\eta = log(\\mu)\\)\r\\(\\mu = e^{\\eta}\\)\r\rGamma\rInverse: \\(\\eta = \\frac{1}{\\mu}\\)\r\\(\\mu = \\frac{1}{\\eta}\\)\r\r\r\r\rThe Exponential Family of Distributions\rA random variable y has a distribution within the exponential family if its probability density function is of the form:\n\\[f(y;\\theta, \\phi) = exp \\left( \\frac{y \\theta - b(\\theta)}{a(\\phi)} + c(y, \\phi) \\right)\\]\nwhere:\n\r\\(\\theta\\) is the location parameter of the distribution\n\r\\(a(\\phi)\\) is the scale/dispersion parameter\n\r\\(c(y, \\phi)\\) is a normalization term\n\r\rIt can also be shown that \\(\\mathop{\\mathbb{E}}[y] = b\u0026#39;(\\theta)\\) and \\(Var[y] = b\u0026#39;\u0026#39;(\\theta) a(\\phi)\\).\n\rLikelihood Analysis and Newton-Raphson Method\rThe fitting of any form of Statistical Learning algorithm involves an optimization problem. Optimization refers to the task of either minimizing or maximizing some function \\(f(\\mathbf{\\beta})\\) by altering \\(\\beta\\). We usually phrase most optimization problems in terms of minimizing \\(f(\\beta)\\). For the case of parametric learning models (we place distributional assumptions on the target/response \\(y_i\\), such that they are drawn independently from some probability distribution \\(p_{model}(y, \\theta)\\)), we we can also use the process of Maximum Likelihood to find model coefficients. Under this approach, we have the following optimization problem:\n\\[\\mathbf{\\beta}^* =arg max(l(y_i | \\mathbf{\\beta}))\\]\nwhere \\(l(y_i)\\) is the likelihood function. The likelihood can be interpreted as the probability of seeing the data in our sample given the parameters and we naturally wish to maximize this quantity to obtain a good model fit.\nWhy Maximum Likelihood?\nThere are several reasons why the process of Maximum Likelihood is preferential:\nSimple and intuitive method to find estimates for any parametric model.\n\rFor large samples, MLE's have useful properties, assuming large n and i.i.d (independent and identically distributed) samples\n\\(\\mathop{\\mathbb{E}}[\\hat{\\theta}_{MLE}] = \\theta\\) (Unbiased)\n\r\\(Var(\\hat{\\theta}_{MLE}) = \\frac{1}{n I(\\theta)}\\), where \\(I(\\theta)\\) is the Fisher Information in the sample. That is, we can calculate the variance of model coefficients and hence perform inference\n\rThe MLE also achieves the Cramer Lower Bound, that is it has the smallest variance of any estimator, thus is Asymptotically Efficient.\n\r\rHowever, there are several disadvantages to Maximum Likelihood, particularly if the purpose of modelling is for prediction. Under Maximum Likelihood, we fit exactly to the training dataset, resulting in overfitting and poor generalization to unseen data.\r\r\rConsider the general form of the probability density function for a member of the exponential family of distributions:\n\\[f(y;\\theta, \\phi) = exp \\left( \\frac{y \\theta - b(\\theta)}{a(\\phi)} + c(y, \\phi) \\right)\\]\nThe likelihood is then (assuming independence of observations):\n\\[L(f(y_i)) = \\prod_{i = 1}^n exp \\left( \\frac{1}{a(\\phi)} (y_i \\theta_i - b(\\theta_i) + c(y_i, \\phi) \\right)\\]\nwith log-likelihood (since the log of the product of exponentials is the sum of the exponentiated terms):\n\\[log(L(f(y_i))) = l(f(y_i)) = \\sum_{i = 1}^n \\frac{1}{a(\\phi)}(y_i \\theta_i - b(\\theta_i)) + c(y_i, \\phi)\\]\nSince the logarithmic function is monotonically increasing, order is preserved hence finding the maximum of the log-likelihood yields the same result as finding the maximum of the likelihood. We wish to maximize this log-likelihood, hence we can differentiate, equate to zero and solve for \\(\\beta_j\\) (We could also ensure the second derivative evaluated at \\(\\beta_j\\) is negative, therefore we have maximized (and not minimized) the log-likelihood). Via the Chain Rule we have:\nEquation 1\n\\[\\frac{\\partial l(f(y_i))}{\\partial \\beta_j} = \\sum_{i = 1}^n \\frac{\\partial l(f(y_i))}{\\partial \\theta_i} \\frac{\\partial \\theta_i}{\\partial \\mu_i} \\frac{\\partial \\mu_i}{\\partial \\eta_i} \\frac{\\partial \\eta_i}{\\partial \\beta_j} = 0\\]\nThis is also known as the Score function, since it tells us how sensitive the model is to changes in \\(\\beta\\) at a given value of \\(\\beta\\). Since we differentiate with respect to each coefficent, \\(\\beta_j\\) (\\(j \\in [0, 1, ..., K]\\)), we have a system of \\((K + 1)\\) equations to solve.\nChain Rule\nThe Chain Rule is often used in Optimization problems. Here we can utilize the chain rule by recognizing that, as seen in 3.1, the likelihood is a function of the location parameter of the distribution, \\(\\theta\\), which in turn is a function of the mean \\(\\mu\\). Via the link function, we have that \\(g(\\mu_i) = \\eta_i\\) and via the linear predictor, \\(\\eta_i = \\beta_0 + \\sum_{i = 1}^{p}\\beta_p x_{i, p}\\).\n\rEach of these individual partial derivatives can then be identified:\n\\[\\frac{\\partial l_i}{\\partial \\theta_i} = \\frac{y_i - b\u0026#39;(\\theta_i)}{a(\\phi)}\\]\n\\[\\frac{\\partial \\theta_i}{\\partial \\mu_i} = \\frac{1}{V(\\mu_i)}\\]\nsince \\(\\frac{\\mu_i}{\\theta_i} = b\u0026#39;\u0026#39;(\\theta_i) = V(\\mu_i)\\) where V is the variance function of the model as it dictates the mean-variance relationship.\n\\[\\frac{\\partial \\mu_i}{\\partial \\eta_i} = \\frac{1}{g\u0026#39;(\\mu_i)}\\]\nsince \\(g(\\mu_i) = \\eta_i \\implies \\frac{\\partial \\eta_i}{\\partial \\mu_i} = g\u0026#39;(\\mu_i)\\). Finally:\n\\[\\frac{\\partial \\eta_i}{\\partial \\beta_j} = x_j\\]\nPutting this all together yields the Maximum Likelihood Equations:\n\\[\\sum_{i = 1}^n \\frac{(y_i - \\mu_i) x_{i, j}}{a(\\phi) V(\\mu_i) g\u0026#39;(\\mu_i)} = 0\\]\nLeast Square Vs Maximum Likelihood If we assume a normal distribution, there are two methods to solve exactly for the coefficients (we could also use Gradient Descent however this does not typically yield an exact solution).\n\rHowever, this does not have a closed form solution (what does it mean for a linear system of equations to have a closed form solultion) (except for the normal distribution). As a sanity check to confirm our conclusions thus far, note that for the normal distribution we have the Normal Equations which have the standard closed form solution (what is it)?. The Maximum Likelihood equations are a set of equations for the regression coefficients \\(\\mathbf{\\beta} = (\\beta_0, ..., \\beta_1)\\)\nEffectively, we need to find coefficients \\(\\beta_j\\) (which for each observation \\(y_i\\) affect our prediction of \\(\\mu_i\\), \\(g\u0026#39;(\\mu_i)\\) and \\(V(\\mu_i)\\) via our distributional assumptions for the relationship between the mean and the variance), such that summing these terms over all observations gives 0. To solve this, we use the Newton - Raphson Method\n\rIteratively Reweighted Least Squares (IRLS)\rRecall the Newton - Raphson method for a single dimension. We wish to find the root of the function (in this case the value of \\(\\beta\\) such that the derivative of the log-likelihood is 0). In One-Dimension, to find the root of function f we have:\n\\[x_{t+1} = x_t - \\frac{f(x_t)}{f\u0026#39;(x_t)}\\]\nThe closer \\(f(x_t)\\) is to 0, the closer we are to the root, hence the step change between iterations will be smaller.\n\r\rInstead of the log-likelihood function \\(f(x)\\), we want to optimize its derivative. Therefore we have the following Newton-Raphson equation in One-Dimension:\n\\[x_{t+1} = x_t - \\frac{f\u0026#39;(x_t)}{f\u0026#39;\u0026#39;(x_t)}\\]\nor for the vector of coefficient estimates at iteration t:\n\\[\\beta_{t+1} = \\beta_t - \\left( \\frac{\\partial l}{\\partial \\beta_j}(\\beta_t) \\right) \\left( \\frac{\\partial^2 l}{\\partial \\beta_j \\partial \\beta_k} \\right)^{-1}\\]\nThe Newton-Raphson technique is derived by considering the Taylor Expansion about the solution \\(\\beta^*\\) (that sets \\(\\frac{\\partial l}{\\partial \\beta}\\) to zero).\n\\[0 = \\frac{\\partial l}{\\partial \\beta}(\\beta^*) - (\\beta - \\beta^*) \\frac{\\partial^2 l}{\\partial \\beta_j \\beta_k} + ...\\]\nIf we ignore all derivative terms higher than \\(2^{nd}\\) order, we can derive and iterative solution. Under the Newton-Raphson approach, the function being minimized is approximated locally by a quadratic function, and this approximated function is minimized exactly. We then have:\n\\[\\beta_{t + 1} = \\beta_t - \\mathbf{H}^{-1}_t \\mathbf{U}_t\\]\nwhere \\(\\mathbf{U}_t is the Score Vector\\) evaluated at \\(\\beta_t\\). \\(\\mathbf{H}_t\\) denotes the (p + 1) x (p + 1) Hessian matrix of second Derivatives\nGiven that \\(\\frac{\\partial l}{\\beta_j} = \\nabla_{\\beta} l = \\frac{(y_i - \\mu_i)}{a(\\phi)} \\frac{x_{i,j}}{V(\\mu_i)}\\frac{1}{g\u0026#39;(\\mu_i)}\\), the Hessian is then:\nEquation 4\n\\[\\nabla^{2}_{\\beta} = \\sum_{i = 1}^n \\frac{x_{i,j}}{a(\\phi)} \\left( (y_i - \\mu_i)\u0026#39; \\frac{1}{g\u0026#39;(\\mu_i)} \\frac{1}{V(\\mu_i)} + (y_i - \\mu_i) \\left( \\frac{1}{g\u0026#39;(\\mu_i)} \\frac{1}{V(\\mu_i)} \\right)\u0026#39; \\right)\\]\nby Product Rule. \\(y_i\\) is a data point so does not depend on \\(\\beta\\).\n\\[\\frac{\\partial \\mu_i}{\\partial \\beta_k} = \\frac{\\mu_i}{\\eta_i} \\frac{\\eta_i}{\\beta_k} = \\frac{1}{g\u0026#39;(\\mu_i)} x_k\\]\nhence the first term becomes:\n\\[\\frac{x_{i,j}}{a(\\phi)} \\left( - \\frac{x_{i, k}}{g\u0026#39;(\\mu_i)} \\right) \\frac{1}{g\u0026#39;(\\mu_i)} \\frac{1}{V(\\mu_i)} = - \\frac{x_{i, j} x_{i, k}}{a(\\phi)(g\u0026#39;(\\mu_i))^2} \\frac{1}{V(\\mu_i)}\\]\nOf course, if we differentiate by the same \\(\\beta\\)-coefficient, we have \\(x_j^2\\), which are values on the diagonal of the Hessian matrix, which recall is \\(\\begin{bmatrix} \\left( \\frac{\\partial ^2 l}{\\partial \\beta_j^2} \\right) \u0026amp; \\left( \\frac{\\partial ^2 l}{\\partial \\beta_k \\partial \\beta_j} \\right)\\\\ \\left( \\frac{\\partial ^2 l}{\\partial \\beta_j \\partial \\beta_k} \\right) \u0026amp; \\left( \\frac{\\partial ^2 l}{\\partial \\beta_k^2} \\right)\\\\ \\end{bmatrix}\\) in 2-Dimensions.\nNow consider the \\(2^{nd}\\) term in equation 4:\n\\[\\left( \\frac{1}{g\u0026#39;(\\mu_i)} \\frac{1}{V(\\mu_i)} \\right)\u0026#39;\\]\nIf we used Newton-Raphson, we would need to calculate this derivative. However, if we use Fisher Scoring, this term cancels out and we don't need to calculate the derivative. Fisher Scoring is a form of Newton's Method used in statistics to solve Maximum Likelihood equations numerically. Instead of usig the inverse of the Hessian, we use the inverse of the Fisher Information matrix:\nFisher Scoring \\[\\beta_{t+1} = \\beta_t = J^{-1} \\nabla l\\] where \\(J = \\mathop{\\mathbb{E}}[- \\nabla^2 l]\\), the expected value of the negative Hessian.\n\rTaking the negative expected value from equation 4, the first term becomes\n\\[\\mathop{\\mathbb{E}} \\left( - - \\frac{x_{i,j} x_{i,k}}{a(\\phi) (g\u0026#39;(\\mu_i))^2} \\frac{1}{V(\\mu_i)} = \\frac{x_{i,j}x_{i,k}}{a(\\phi) (g\u0026#39;(\\mu_i))^2} \\frac{1}{V(\\mu_i)}\\]\nsince none of the above values depende on \\(y\\) hence are all constant. The \\(2^{nd}\\) term in equation 4 becomes:\n\\[\\mathop{\\mathbb{E}} \\left( - \\frac{x_{i,j}}{a(\\phi)}(y_i - \\mu_i) \\left( \\frac{1}{g\u0026#39;(\\mu_i) V(\\mu_i)} \\right) \u0026#39; \\right) = - \\frac{x_{i,j}}{a(\\phi)}(y_i - \\mu_i) \\left( \\frac{1}{g\u0026#39;(\\mu_i) V(\\mu_i)} \\right)\u0026#39; \\mathop{\\mathbb{E}}(y_i - \\mu_i)\\]\nbut this expectation is equal to zero and the second term therefore vanishes. We then have:\n\\[J = \\sum_{i = 1}^n \\frac{x_{i,j} x_{i,k}}{a(\\phi) (g\u0026#39;(\\mu_i))^2 \\frac{1}{V(\\mu_i)}} = \\mathbf{X}^T \\mathbf{W} \\mathbf{X}\\]\nThis can be rewritten as:\n\\[J = \\mathbf{X}^T \\mathbf{W} \\mathbf{X}\\]\nwhere\n\\[\\mathbf{W} = \\frac{1}{a(\\phi)} \\begin{bmatrix} \\frac{1}{V(\\mu_1)} \\frac{1}{(g\u0026#39;(\\mu_1))^2} \u0026amp; \u0026amp; \\\\ \u0026amp; ... \u0026amp; \\\\ \u0026amp; \u0026amp; \\frac{1}{V(\\mu_n)(g\u0026#39;(\\mu_n))^2}\\\\ \\end{bmatrix}\\]\nFrom Fisher Scoring, we have:\n\\[\\mathbf{\\beta}_{t+1} = \\mathbf{\\beta_t} = \\mathbf{J}^{-1} \\nabla_{\\beta} l (\\beta_t)\\]\nWe can rewrite \\(\\nabla_{\\beta}l = \\sum_{i = 1}^n \\frac{y_i - \\mu_i}{a(\\phi)} frac{1}{a(\\phi)} \\frac{x_{i,j}}{V(\\mu_i g\u0026#39;(\\mu_i))}\\) as \\(\\mathbf{X}^T \\mathbf{D} \\mathbf{V}^{-1} (y - \\mu)\\) where:\n\\[\\mathbf{D} = \\begin{bmatrix} \\frac{1}{g\u0026#39;(\\mu_1)} \u0026amp; \u0026amp; \\\\ \u0026amp; ... \u0026amp; \\\\ \u0026amp; \u0026amp; \\frac{1}{g\u0026#39;(\\mu_n)} \\\\ \\end{bmatrix}\\]\n\\[\\mathbf{V}^{-1} = \\frac{1}{a(\\phi)} \\begin{bmatrix} \\frac{1}{V(\\mu_1)} \u0026amp; \u0026amp; \\\\ \u0026amp; ... \u0026amp; \\\\ \u0026amp; \u0026amp; \\frac{1}{V(\\mu_n)} \\\\ \\end{bmatrix}\\]\nThen for the Fisher Equation we have:\n\\[\\mathbf{\\beta}_{t+1} = \\mathbf{\\beta}_t + (\\mathbf{X}^T \\mathbf{W} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{D} \\mathbf{V}^{-1} (\\mathbf{y} - \\mathbf{\\mu})\\]\nWe can write this more generally, by noting that \\(\\mathbf{W}\\) is the same as \\(\\mathbf{D} \\mathbf{V}^{-1}\\), except we have \\(\\frac{1}{(g\u0026#39;(\\mu_i))^2}\\).\n\\[\\implies \\mathbf{D} \\mathbf{V}^{-1} = \\mathbf{W M}\\]\nwhere\n\\[\\mathbf{M} = \\begin{bmatrix} \\frac{1}{g\u0026#39;(\\mu_1)} \u0026amp; \u0026amp; \\\\ \u0026amp; ... \u0026amp; \\\\ \u0026amp; \u0026amp; \\frac{1}{g\u0026#39;(\\mu_1)} \\\\ \\end{bmatrix}\\]\n\\[\\implies \\beta_{t + 1} = \\beta_t + (X^T W X)^{-1} X^T W M (y - \\mu)\\]\nWe can already calculate each of these terms and thus generate an iterative model-fitting algorithm. We can update the \\(\\beta\\)'s until convergence of the algorithm. We can then simplify the equation:\n\\[\\beta_{t+1} = (X^T W X)^{-1} (X^T W X) beta_t + (X^T W X)^{-1} X^T W M (y - \\mu) =\r(X^T W X)^{-1} X^T W (X \\beta_t + M (y - \\mu)) = (X^T W X)^{-1} X^T W Z_t\\]\nwhere \\(Z_t := \\eta_t + M(y - \\mu)\\)\nThis is \u0026quot;iteratively Reweighted Least Squares\u0026quot;- at each iteration we are solving a weighted least squares problem, is iterative because we update W's and Z's at the same time. The amount the algorithm updates depends on two things- \\(Z_t\\) and \\(W\\). For \\(Z_t\\), larger deviation between \\(y\\) and \\(\\mu\\) results in larger steps in the iteration procedure. Unless we have a saturated model, \\(y \\not \\mu\\) (observed values don't equal predicted values), there is a trade-off as we vary \\(\\beta\\), resulting in different discrepencies between \\(y_i\\) and \\(\\mu_i\\).\nThe Hessian is a matrix of second derivatives of the log-likelihood function, that is, derivatives of the derivative of the log-likelihood function. The second derivative therefore measures curvature, that is how much the first derivative changes as we vary the input. If the likelihood has a second derivative of zero, then the likelihood (cost function) is a flat line, so its value can be predicted using only the gradient. If the gradient is 1, a step size of \\(\\epsilon \u0026gt; 0\\) then the likelihood function will increase by the value of \\(\\epsilon\\). If the \\(2^{nd}\\) derivative is negative (the gradient of the likelihood function is becoming more negative fo an increase \\(\\epsilon\\) at \\(x\\)), the likelihood function curves downwards, so the likelihood will decrease by more than \\(\\epsilon\\). That is, the likelihood decreases faster than the gradient predicts for small \\(\\epsilon\\).\nWhen our function has multiple input dimensions, there are many \\(2^{nd}\\) derivatives (one for each feature and then for each feature crossed with every other feature), and can be collected in a matrix called the Hessian. If we look at the IRLS equation, we have 3 terms. Firstly, we have the original value of the function, the expected improvement due to the slope of the function and a correction we must apply to account for the curvature of the function. When this last term is too small, the likelihood step can actually move downhill.\nDerivation of Model Fitting Algorithms/Coefficients This derivation of Iteratively Reweighted Least Squares for GLMs follows a similar procedure to the derivation of any model fitting algorithm. Firstly, we identify an objective function over which to optimize. Typical Machine Learning problems involve minimizing some loss function, which gives discrepencies between the actual and true values. We then differentiate this function to find a minimum and use Newton - Raphson ... What other algorithms are there for fitting other models and how are their model-fitting algorithms derived?\n\rWhy Bother with Parametric Assumptions\nAdvantages - Large amounts of data can be modelled as random variables from the exponential family of distributions - If there are relatively few observations, providing a structure for the model generating process can improve predictive performance - Enables us to carry out inference on model covariates - Simple and intuitive to understand. In some industries (such as insurance), this has huge benefits- it is transparent and can fit into a rate structure\nDisadvantages - Validity of inference dependent on assumptions being satisfied - Places a very rigid structure - Typically has worse predictive performance than non-linear models, such as Boosted Trees and Neural Networks.\n\r\rIRLS Implementation\rIn the following, we implement IRLS for Generalized Linear Models (GLMs). We could also write in C++ for a more efficient implementation.\n\r","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2eb203de310acaf0bb7c42cbb9248eba","permalink":"https://domscruton.github.io/post/glm-irls/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/glm-irls/","section":"post","summary":"GLMs - A Natural Extension of the Linear Model\rThe first model we naturally learn on any statistics-based course is Simple Linear Regression (SLR). Despite placing strong (linear) assumptions on the relationship between the response and covariates, as well as the error distribution if we are interested in statistical inference, the Linear model is a surprisingly useful tool for representing many natural processes.","tags":null,"title":"GLMs: Intuition behind the Link function and Derivation of Iteratively Reweighted Least Squares","type":"post"}]